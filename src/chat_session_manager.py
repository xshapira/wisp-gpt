import json
from pathlib import Path

import streamlit as st
from langchain_core.messages import messages_from_dict, messages_to_dict
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from src.utils import load_file


def save_message(message, role):
    """
    Saves a message and its corresponding role (e.g., "ai") to the session state.
    """
    st.session_state["messages"].append({"message": message, "role": role})


def send_message(message, role, save=True):
    """
    Sends a message to a specific role in a chat and optionally saves the message.

    Args:
        message: The content of the message that you want to send. It can
        be a string or any other data type that can be converted to a string.
        role: The role or identity of the sender of the message. It can be any string value that represents the role, such as "ai", "assistant", etc.
        save: A boolean flag that determines whether or not to save the message. If `save` is set to `True`, the message will be saved using the `save_message` function.
    """
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)


def display_chat_history():
    """
    Displays the chat messages without saving them.
    """
    for message in st.session_state["messages"]:
        send_message(message["message"], message["role"], save=False)


def save_history(input, output):
    """
    Save the chat history by appending the input and output to the session state.

    Args:
        input: The user's input or message in a chat conversation.
        output: The response or output generated by the chatbot or the
        system based on the given input. It could be a text message,
        a recommendation, a prediction, or any other form of output generated by the system.
    """
    st.session_state["chat_history"].append(
        {"input": input, "output": output},
    )


def calculate_similarity(new_entry, existing_entries):
    """
    Calculates similarity of the new entry against existing entries using TF-IDF and cosine similarity.

    Args:
        new_entry: The new entry to be checked.
        existing_entries: The list of existing history entries.

    Returns:
        True if a similar entry exists, False otherwise.
    """
    documents = [entry["data"]["content"] for entry in existing_entries]
    # proceed only if there are at least two documents to compare
    if len(documents) > 1:
        vectorizer = TfidfVectorizer()
        tfidf_matrix = vectorizer.fit_transform(documents)

        # compare the new entry (last in tfidf_matrix)
        # to all previous entries
        cosine_similarities = cosine_similarity(
            tfidf_matrix[-1], tfidf_matrix[:-1]
        ).flatten()
        return any(similarity > 0.8 for similarity in cosine_similarities)

    # if there's not enough data to compare, return False
    return False


def save_history_to_file(history_file_path):
    """
    Saves the chat history to a file in JSON format.

    Args:
        history_file_path: The file path where you want to save the chat history. It should be a string representing the file path.
    """
    history_file = Path(history_file_path)
    history = st.session_state["memory"].chat_memory.messages
    history = messages_to_dict(history)

    if history_file.exists():
        # file exists, read the existing content first
        with open(history_file) as fp:
            existing_history = json.load(fp)

        for entry in history:
            if not calculate_similarity(entry, existing_history):
                existing_history.append(entry)
        # update existing history with new content
        updated_history = existing_history
    else:
        # history doesn't exists, create new history
        updated_history = history

    # write the updated history to the file
    with open(history_file, "w") as fp:
        json.dump(updated_history, fp, indent=2)


def restore_history_from_memory():
    """
    Restores chat history from memory by saving the input and output context.
    """
    for history in st.session_state["chat_history"]:
        st.session_state["memory"].save_context(
            {"input": history["input"]},
            {"output": history["output"]},
        )


@st.cache_data(show_spinner="Loading history from file...")
def load_history_from_file(history_file_path):
    """
    Loads chat history from a file and updates the chat memory.

    Args:
        history_file_path: A string that represents the file path of the history file that you want to load. This file should contain the chat history data in a JSON format.
    """
    loaded_message = load_file(history_file_path)
    history = messages_from_dict(loaded_message)
    st.session_state["memory"].chat_memory.messages = history
